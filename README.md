# K-Nearest Neighbors para OCR

Neste projeto, utilizamos o algoritmo <strong>k-Nearest Neighbors (k-NN)</strong> para realizar o reconhecimento automÃ¡tico de caracteres do alfabeto IorubÃ¡ a partir de imagens prÃ©-processadas. Esse processo se enquadra no contexto de <strong>OCR (<em>Optical Character Recognition</em>)</strong>, onde o objetivo Ã© identificar o caractere representado pela imagem. O k-NN foi escolhido por ser um mÃ©todo simples, interpretÃ¡vel e eficiente em problemas de classificaÃ§Ã£o baseados em similaridade.

## Participantes

Artur Massaro Cremonez  
Bruno Henrique Silva Viola

---

## O que foi feito?

Iniciamos pelo prÃ©-processamento, realizando a conversÃ£o das imagens para a escala de cinza. ConstruÃ­mos a possibilidade de recorte das bordas brancas dos caracteres (essa opÃ§Ã£o deve ser ativada por uma flag). Por fim, executamos o redimensionamento das imagens para `32x32` pixels.

---

## Estrutura do RepositÃ³rio

Outros experimentos foram realizados com diferentes resoluÃ§Ãµes de imagem (`16x16`, `64x64`, `128x128`, etc.). Os resultados podem ser encontrados nas pastas:

- ğŸ“ `matrizes_de_confusao/`
- ğŸ“ `metricas_por_classe/`
- ğŸ“ `relatorios_classificacao/`

---

## Metodologia

- ğŸ” Algoritmo: `KNeighborsClassifier` com `k=5`
- ğŸ” ExecuÃ§Ã£o em **10 iteraÃ§Ãµes** com seeds diferentes
- ğŸ”€ DivisÃ£o dos dados: **80% treino / 20% teste**
- ğŸ“‰ Imagens achatadas (`flatten`) para entrada no modelo

MÃ©tricas de AvaliaÃ§Ã£o: Foram avaliadas duas categorias de mÃ©tricas.

- ğŸ“Š **MÃ©tricas gerais (mÃ©dias ao final das 10 iteraÃ§Ãµes):**
  - AcurÃ¡cia
  - PrecisÃ£o
  - RevocaÃ§Ã£o
  - F1-Score

- ğŸ“ˆ **MÃ©tricas por classe:**
  - PrecisÃ£o por classe
  - RevocaÃ§Ã£o por classe
  - F1-Score por classe

---

## Pipeline

### â–¶ï¸ PrÃ©-processamento

- ConversÃ£o para escala de cinza
- Possibilidades:
  - AdequaÃ§Ã£o de cores
  - AdequaÃ§Ã£o de dimensÃµes
  - Balanceamento entre as classes (via data augmentation)
  - EstruturaÃ§Ã£o dos dados por classe

### â–¶ï¸ Treinamento/Teste

- ExecuÃ§Ã£o do KNN por 10 iteraÃ§Ãµes
- Registro de mÃ©tricas por iteraÃ§Ã£o e por classe
- Salvar arquivos com resultados em `.txt`, `.png`, etc.

### â–¶ï¸ PÃ³s-processamento

- GeraÃ§Ã£o de grÃ¡ficos e matrizes de confusÃ£o acumuladas
- NomeaÃ§Ã£o dos arquivos com tags indicando as configuraÃ§Ãµes (e.g., `COM_DataAug`, `Bordas_REMOVIDAS`)

---

## Resultados

### ğŸ“Œ CenÃ¡rio 1: **Sem Data Augmentation, Sem Recorte de Bordas**

- ğŸ“ [`relat_32x32_SEM_DataAug_Bordas_NAO_REMOVIDAS.txt`](relatorios_classificacao/relat_32x32_SEM_DataAug_Bordas_NAO_REMOVIDAS.txt)  
- ğŸ“Š Matriz de confusÃ£o:![](matrizes_de_confusao/mc_32x32_SEM_DataAug_Bordas_NAO_REMOVIDAS.png)  
- ğŸ“ˆ MÃ©tricas por classe:![](metricas_por_classe/mpc_32x32_SEM_DataAug_Bordas_NAO_REMOVIDAS.png)

| MÃ©tricas (apÃ³s 10 iteraÃ§Ãµes) | Valor   |
|------------------------------|---------|
| AcurÃ¡cia mÃ©dia               | 0.9434  |
| PrecisÃ£o mÃ©dia               | 0.9139  |
| RevocaÃ§Ã£o mÃ©dia              | 0.8620  |
| F1-Score mÃ©dio               | 0.8801  |

---

### ğŸ“Œ CenÃ¡rio 2: **Com Data Augmentation, Sem Recorte de Bordas**

#### Data Augmentation

Para lidar com desbalanceamento entre classes, aplicamos transformaÃ§Ãµes aleatÃ³rias no conjunto de treino:

- ğŸ”„ RotaÃ§Ã£o aleatÃ³ria entre -10Â° e +10Â°  
- ğŸ’¡ Brilho entre 0.5 e 1.5  
- ğŸšï¸ Contraste entre 0.5 e 1.5  
- âœ¨ Nitidez entre 0.5 e 1.5  

Objetivo: garantir **300 exemplos por classe**.

- ğŸ“ [`relat_32x32_COM_DataAug_Bordas_NAO_REMOVIDAS.txt`](relatorios_classificacao/relat_32x32_COM_DataAug_Bordas_NAO_REMOVIDAS.txt)  
- ğŸ“Š Matriz de confusÃ£o:![](matrizes_de_confusao/mc_32x32_COM_DataAug_Bordas_NAO_REMOVIDAS.png)  
- ğŸ“ˆ MÃ©tricas por classe:![](metricas_por_classe/mpc_32x32_COM_DataAug_Bordas_NAO_REMOVIDAS.png)

| MÃ©tricas (apÃ³s 10 iteraÃ§Ãµes) | Valor  | Ganho/Perda em relaÃ§Ã£o ao cenÃ¡rio 1 |
|------------------------------|--------|-------------------------------------|
| AcurÃ¡cia mÃ©dia               | 0.9649 | + 0.0215                            |
| PrecisÃ£o mÃ©dia               | 0.9409 | + 0.0270                            |
| RevocaÃ§Ã£o mÃ©dia              | 0.9449 | + 0.0829                            |
| F1-Score mÃ©dio               | 0.9395 | + 0.0594                            |

---

### ğŸ“Œ CenÃ¡rio 3: **Com Data Augmentation e Recorte de Bordas**

- ğŸ“ [`relat_32x32_COM_DataAug_Bordas_REMOVIDAS.txt`](relatorios_classificacao/relat_32x32_COM_DataAug_Bordas_REMOVIDAS.txt)  
- ğŸ“Š Matriz de confusÃ£o:![](matrizes_de_confusao/mc_32x32_COM_DataAug_Bordas_REMOVIDAS.png)  
- ğŸ“ˆ MÃ©tricas por classe:![](metricas_por_classe/mpc_32x32_COM_DataAug_Bordas_REMOVIDAS.png)

| MÃ©tricas (apÃ³s 10 iteraÃ§Ãµes) | Valor  | Ganho/Perda em relaÃ§Ã£o ao cenÃ¡rio 2 |
|------------------------------|--------|---------------------------|
| AcurÃ¡cia mÃ©dia               | 0.9817 | + 0.0168                  |
| PrecisÃ£o mÃ©dia               | 0.9746 | + 0.0337                  |
| RevocaÃ§Ã£o mÃ©dia              | 0.9789 | + 0.0340                  |
| F1-Score mÃ©dio               | 0.9748 | + 0.0353                  |

---

## ConclusÃ£o

Mesmo com um classificador simples como o KNN, obtivemos Ã³timos resultados no reconhecimento de caracteres iorubÃ¡s. As tÃ©cnicas aplicadas no prÃ©-processamento tiveram papel fundamental no desempenho do modelo.

A combinaÃ§Ã£o de **data augmentation** com **recorte das bordas** resultou no melhor cenÃ¡rio testado, atingindo uma acurÃ¡cia mÃ©dia de **98.17%**. Esses resultados demonstram que o cuidado com o tratamento das imagens pode ser tÃ£o ou mais importante que a escolha do algoritmo em si, especialmente em tarefas de classificaÃ§Ã£o visual com dados desbalanceados.

AlÃ©m disso, foi possÃ­vel observar que letras com poucos exemplos, que inicialmente nÃ£o eram reconhecidas, passaram a ser corretamente classificadas com o uso do **data augmentation** e melhoraram ainda mais apÃ³s o recorte das bordas. Isso reforÃ§a a importÃ¢ncia dessas etapas para garantir que todas as classes sejam representadas e avaliadas de forma justa.

---

